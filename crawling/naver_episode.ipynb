{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "import pymysql\n",
    "import re\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# mysql db connect\n",
    "db = pymysql.connect(host='52.78.23.232', user='root', password='readers7', port=3306, db='readers', charset='utf8', cursorclass=pymysql.cursors.DictCursor)\n",
    "# browser = webdriver.Chrome('C:/Users/KSY/Documents/GitHub/Readers/crawling/chromedriver.exe')\n",
    "cursor1 = db.cursor()\n",
    "cursor2 = db.cursor()\n",
    "cursor3 = db.cursor()\n",
    "cursor4 = db.cursor()\n",
    "\n",
    "#웹 페이지를 열고 소스코드를 읽어오는 작업\n",
    "def readHtml(url):\n",
    "    # print(url)\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    html.close()\n",
    "    return soup\n",
    "\n",
    "### 네이버 웹툰 회차정보 크롤링 ###\n",
    "\n",
    "sel_url_sql = 'select toon_id, toon_url from toon_info where toon_site = \"naver\"'\n",
    "sel_dup_sql = 'select toon_id, epi_name from epi_info where toon_id = %s and epi_name = %s'\n",
    "ins_epi_info_sql = 'insert into epi_info(toon_id, epi_name, epi_url, epi_thumb_url, epi_date)\\\n",
    "                    values (%s, %s, %s, %s, %s)'\n",
    "\n",
    "cursor1.execute(sel_url_sql)\n",
    "result = cursor1.fetchall()\n",
    "   \n",
    "for row in result:\n",
    "    toon_id = row['toon_id']\n",
    "    toon_url = row['toon_url']\n",
    "    \n",
    "    num = 1 # 페이지 탐색용\n",
    "    have_to_break = 0 # 루프 탈출용\n",
    "    \n",
    "    while 1:\n",
    "        real_url = toon_url+str(num) # 실제 웹툰 링크, 첫 페이지부터\n",
    "        num = num + 1 # 다음 페이지 탐색을 위해\n",
    "        soup = readHtml(real_url)\n",
    "\n",
    "        webtoon_area = soup.find(\"table\", {\"class\": \"viewList\"}).findAll('tr')\n",
    "        \n",
    "        if (have_to_break == 1):\n",
    "            break\n",
    "        \n",
    "        for index in webtoon_area:\n",
    "            info = index.find('a')\n",
    "            if (index.find('a')):\n",
    "                if (index.find('td', {'class' : 'num'})):\n",
    "                    info = index.find('a')\n",
    "                    epi_url = \"https://comic.naver.com\" + info['href'] # 에피소드 링크 추출\n",
    "                    img = info.find('img')\n",
    "                    epi_thumb_url = img['src'] # 썸네일 링크 추출\n",
    "                    epi_name = img['title'] # 에피소드 제목 추출\n",
    "                    date = index.find('td', {'class' : 'num'}).get_text()\n",
    "                    epi_date = date.replace(\".\", \"-\") # 업데이트 날짜 추출\n",
    "                    \n",
    "                    cursor2.execute(sel_dup_sql, (toon_id, epi_name))\n",
    "                    if cursor2.fetchall():\n",
    "                        have_to_break = 1\n",
    "                        break\n",
    "    \n",
    "                    else:\n",
    "                        cursor3.execute(ins_epi_info_sql, (toon_id, epi_name, epi_url, epi_thumb_url, epi_date))\n",
    "                        db.commit()\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
